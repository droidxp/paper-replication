\section{Introduction}

Almost two-thirds of the world population use mobile technologies \cite{Comscore}, and Android Operating System has dominated this marketplace of smartphones, tablets, and others electronic devices. Due to this growing popularity, the number of incidents related to Android malicious software (malware) has significantly increased \cite{faruki2014android,tan2015securing}. Security issues in (commonly known as "apps") have become a relevant research topic, and many techniques have been developed to identify vulnerabilities in Android apps \cite{tan2015securing}. For instance, researchers have explored the use of dynamic analysis tools and test case generators to mine sandboxes, whose goal is to protect Android users from malicious behaviors \cite{jamrozik2016mining}.

The main idea of mining sandboxes is to explore the set of calls to sensitive API methods, using automated tools for testing. These tools, explore apps behaviors based on their sensitive APIs. A sandbox builds upon the calls to sensitive Android APIs, during the execution of test cases (exploratory phase). The sandbox could then block future calls to other sensitive resources, which diverge from those found in the exploratory phase. Using this approach, the sandbox accuracy depends on the exploratory capabilities of each testing tool used to mine the sandbox rules.

A previous work has argued in favor of dynamic analysis for mining sandboxes, instead of using static analysis \cite{jamrozik2016mining}. The authors claim that dynamic analysis exceeds static analysis on mining Android sandboxes domain because the analysis must often assume that more behaviors are possible than actually would be, and if static analysis determine that some behavior is impossible, this behavior no longer needs to be checked at runtime. Thereby, code that is interpreted, decrypted, or downloaded at run time is challenging for static analysis. However, they do not provide any empirical validation about this claim, and there was no effective discussion about the possibility of combination of both proposals. Moreover, Bao et al. \cite{bao2018mining} present an empirical study comparing different dynamic analysis tools for mining sandboxes, that leverage DroidFax \cite{cai2017droidfax} to instrument 102 pairs of Android apps (each pair comparing a benign and a malign version of an App), and collect information needed to mine sandboxes. Although the authors report an efficient in identifying 70\% of the malware in this specific dataset, part of this result is due to an internal static analysis algorithm of DroidFax, which might improve the performance of the dynamic analysis tools for mining sandboxes, introducing a possible threat to the work.

Hence, in this paper we further dig into the role of static analysis order for malware detecting. Specifically, we aim at understanding how static analysis might be useful and help dynamic analysis in the process of mining android sandboxes. To this end, we conducted a non-exact replication of the study of Bao et al, supported by a benchmark solution, called droidXP \cite{dadroidxp}, whose main objective is assist researchers and practitioners to integrate test case generation tools and compare their performance on mining android sandboxes. Our study differs from the original in the following aspects. First, we refined the dataset used, and executed the analysis of each apps, for a time biggest than the original experiment. Second, we introduced in our study, two tools that were not considered in the previous work. Finally, we evaluate the role of each kind of analysis, static and dynamic, regarding the performance of the analyzed tools.

Altogether, this paper contributes to comprehend the role of each of the analyzes in the malware detection task by:

\begin{enumerate}[(1)]
 \item presenting a non-exact replication of the study of the efficiency of test generation tools for mining android sandboxes, using a benchmark solution developed for this specific purpose.
 
 \item discovering which are the contribution installments of types of analysis for malware detection task.
 
 \item presenting which are malware characteristics, that was not detected by any tool in our analysis dynamic and static experiment.
 
 \item presenting data that indicate that static analysis can improve the mining sandboxes process for malware detection.
 \end{enumerate}
 
We organize the remainder of this paper as follows. Section 2 we present a background and some related works. Section 3 describes all the apps malware used in our experiment, presenting their characterization. Section 4 introduces the study setting of our research. Section 5 presented some results, highlighting some motivation malware example. Section 6 we present the use of a promising static analysis tool, in our motivation example. Finally, Sections 7 and 8, summarizes the paper, discussing our ideas for future works, and presenting the final conclusions.
